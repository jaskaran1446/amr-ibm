[GraphOutputs]
evals = deptree

[FormTokenVocab]
cased = False
min_occur_count = 2
embed_size = 100

[FormPretrainedVocab]
cased = False
max_embed_count = 0
linear_size = 100

[FormMultivocab]
use_token_vocab = True
use_pretrained_vocab = True
use_subtoken_vocab = True
combine_func = reduce_sum
embed_keep_prob = .67
drop_func = dropout

[UPOSTokenVocab]
cased = True
embed_size = 100
embed_keep_prob = .67
drop_func = dropout

[XPOSTokenVocab]
cased = True
embed_size = 100
embed_keep_prob = .67
drop_func = dropout

[DeprelTokenVocab]
factorized = True
loss_interpolation = .5
n_layers = 1
diagonal = False
add_linear = True
hidden_size = 100
hidden_keep_prob = .67
hidden_func = leaky_relu

[DepheadIndexVocab]
n_layers = 1
diagonal = False
hidden_size = 400
hidden_keep_prob = .67
hidden_func = leaky_relu
add_linear = True

[BaseNetwork]
max_steps_without_improvement = 5000
sum_pos = True

highway = False
drop_type = recurrent
conv_keep_prob = .67
recur_keep_prob = .67
n_layers = 3
first_layer_conv_width = 0
conv_width = 0
recur_size = 200
l2_reg = 0
print_every = 100
switch_optimizers = False

[TaggerNetwork]
input_vocabs = FormMultivocab
output_vocabs = UPOSTokenVocab:XPOSTokenVocab:UFeatsFeatureVocab
throughput_vocabs = LemmaTokenVocab:DepheadIndexVocab:DeprelTokenVocab
conv_keep_prob = .5

[ParserNetwork]
input_vocabs = FormMultivocab:UPOSTokenVocab:XPOSTokenVocab
output_vocabs = DepheadIndexVocab:DeprelTokenVocab
throughput_vocabs = LemmaTokenVocab:UFeatsFeatureVocab

#===============================================================
# Subtoken vocabs
[SubtokenVocab]
cased = True
special_token_case = upper
special_token_html = True
min_occur_count = 1
max_buckets = 2
token_vocab_loadname = 
# neural
embed_size = 100
embed_keep_prob = 1.
conv_keep_prob = .67
recur_keep_prob = .67
recur_include_prob = 1.
output_keep_prob = .67
n_layers = 1
first_layer_conv_width = 0
conv_width = 0
recur_size = 400
bidirectional = False
recur_cell = LSTM
recur_func = tanh
output_func = identity
cifg = False
highway = False
highway_func = identity
bilin = False
squeeze_type = final_state
output_size = 100

[Optimizer]
learning_rate = .002
mu = .9
nu = .9

